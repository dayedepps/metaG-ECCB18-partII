\documentclass{scrartcl}
\usepackage[utf8]{inputenc}

\title{MetaG ECCB'18 tutorial}
\subtitle{Part II: large scale sequence analysis}
\author{Clovis Galiez, Milot Mirdita, Johannes SÃ¶ding}
\date{Sept. 2018}

\usepackage{natbib}
\usepackage{url}
\usepackage{graphicx}
\usepackage[]{minted}
\usepackage{tcolorbox}
\usepackage{etoolbox}
\BeforeBeginEnvironment{minted}{\begin{tcolorbox}}
\AfterEndEnvironment{minted}{\end{tcolorbox}}
\usepackage{courier}

\begin{document}

\maketitle

\section{Introduction}
MMseqs2 (Many-against-Many sequence searching \citep{steinegger2017mmseqs2}) is a software suite to search and cluster huge protein sequence sets. MMseqs2 is open source GPL-licensed software implemented in C++ for Linux, MacOS, and (as beta version, via cygwin) Windows. The software is designed to run on multiple cores and servers and exhibits very good scalability. MMseqs2 can run 10000 times faster than BLAST. At 100 times its speed it achieves almost the same sensitivity. It can perform profile searches with the same sensitivity as PSI-BLAST at over 400 times its speed.

\begin{figure}[h!]
\centering
\includegraphics[height=70mm]{mmseqs2_logo.png}
\caption{MMSeqs2, your new friend.}
\label{fig:universe}
\end{figure}

You will learn here the basic usage of MMSeqs2 as well as expert trick to take advantage of the ability of chaining different MMSeqs2 modules to produce custom workflows. We will show on an human gut metagenomic dataset (SRA run \texttt{ERR1384114}) what are the advantages of using MMseqs2 and Plass (Protein Level Assembly) over the more conventional pipeline MegaHit\citep{li2015megahit}+Prodigal\citep{hyatt2010prodigal}+Diamond.



\section{Set up and discover your environment}

\subsection{Command line interface and software}
You will work on your own remote machine through a Bash terminal in your browser. Please connect to your machine following this link: \url{https://17.llil.de/ide.html}.
All software and data has been installed before this tutorial. The commands to reproduce the installation is available in the \texttt{scripts/setup.sh} GitHub of the tutorial \url{https://github.com/soedinglab/metaG-ECCB18-partII}.

All the software is already installed in \texttt{$\sim$/software} and intergated in your \texttt{\$PATH} environment variable, and you will find the raw Fastq sequence file in the directory \texttt{$\sim$/data}.

You can take a look to the helper of the following commands:
\begin{minted}{bash}
plass
mmseqs
megahit -h
\end{minted}



\section{Analysis of a human gut metaG dataset}
\subsection{Getting a catalog of proteins}

We propose to use Plass to assemble a catalog of protein sequences directly from the reads, without the nucleic assembly step that prevent many reads to assemble due to low \textbf{coverages} and \textbf{microdiversity}. Use the command \begin{minted}{bash}
plass assemble readsFastqFile plassProteins.faa tmpDir
\end{minted}

or type \texttt{plass assemble -h} for more options.

\vspace{10pt}
As a matter of comparison, run the usual pipeline using MegaHit for nucleic assembly (\texttt{megahit -r readsFastqFile -o megahitAssemblyDir}), and then extracting the proteins using Prodigal (\texttt{prodigal -i contigFile.fna -a prodigal.faa}.
Take a look to the fasta files produced by Plass and Prodigal, or directly compare the number of detected proteins using (don't forget the quotes there ;) ): \begin{minted}
{bash}
grep -c ">" file.faa
\end{minted}

There is actually some redundancy in the catalog generated by Plass. You can reduce this catalog by clustering it for instance to 90\% of sequence identity and asking for the representative to cover at least 95\% of the members:
\begin{minted}{bash}
mmseqs easy-cluster plassProteins.faa clusteredProts.faa \ 
tmpDir --min-seq-id 0.9 -c 0.95 --cov-mode 1 
\end{minted}
You can count the number of entries in your clustered fasta file \texttt{clusteredProts.faa} again using \texttt{grep} command.

The \textit{easy-cluster} command is a shorthand for dealing with fasta files as input and output. However, MMSeqs2 natively \textbf{does not} deal with Fasta format. It prefers the efficient FFindex format. Since the goal is to make you an expert in the MMSeqs2 workflow, we will now only deal with FFindex database and create fasta files only when needed.

You can convert a Fasta to am FFindex using:
\begin{minted}
{bash}
mmseqs createdb plassProteins.faa plassProteinsDb
\end{minted}

This generated two files: a \textit{data} file plassProteinsDb together with an \textit{index} file plassProteinsDb.index. The first file contains all the sequences separated by a null byte \texttt{\textbackslash0}. We coin more generally any data record \textit{an entry}, and each entry has a unique \textit{key} (integer number) that is stored in the \textit{index} file.

The format of this index file is tab-separated and reports one line per entry in the database, specifying a unique key (column 1), the offset and the length of the corresponding data (columns 2 and 3 respectively). As we will make use of the efficient structure later on in the tutorial, you can already take a look to the index file structure with:
\begin{minted}
{bash}
head plassProteinsDb.index
\end{minted}

Let's re-run the clustering of the catalog database with our fresh FFindex database:
\begin{minted}
{bash}
mmseqs cluster plassProteinsDb plassProteinsReduced \
--min-seq-id 0.9 -c 0.95 --cov-mode 1 
\end{minted}
This creates a \textit{cluster database} where each entry has the key of its representative sequence, and each entry  contains the key of its members:
\begin{minted}
{bash}
# you will see the keys belonging to different clusters
# separated by a null byte (shown as a ^@ in vi)
vi plassProteinsReduced
\end{minted}

\textit{Note that this is a general principle in MMseqs that the keys are always consistent between the input, output and potentially intermediate files}.

Therefore, to count the number of proteins left in the clustered database, you can count the number of entries using:
\begin{minted}
{bash}
wc -l plassProteinsReduced.index
\end{minted}

\subsection{Annotating the catalog}

To get annotation of your protein catalog, we propose to search the sequences against a database of Pfam profiles:
\begin{minted}
{bash}
# -s 7 for high sensitivity
time mmseqs search plassProteinsReduced ~/databases/pfamProfiles \
searchOutProfile.mmseqs tmp -s 7 --no-preload
\end{minted}


You can compare (time and number of annotation) with the HMMER tool:
\begin{minted}
{bash}
time hmmscan --notextw --noali --tblout "hmmer.tblout"\
--domtblout "hmmer.domtblout"\
~/databases/Pfam-A.full_hmmer clusteredProts.faa 

# check the number of annotated proteins
tail -n+4 hmmer.tblout |cut -c 21-30|sort -u|wc -l 
\end{minted}


A full benchmark between the precision and sensitivity is available at \url{TODO: link to Milot's paper when avail}.




\section{Build you own workflows}
\subsection{Cascaded profile clustering (deep clustering)}


We will see how we can take advantage of the MMSeqs2 modular structure for creating a workflow (bash script) that call MMSeqs2 tools to deeply cluster a set of proteins. 
The simplest idea is to create a cascaded clustering workflow: after a first clustering step, the representative sequences of each of the clusters are searched against eachother and the result of the search is again clustered. By repeating iteratively this procedure, one gets a deeper clustering of the original set.

Try to code yourself the following partial pseudo-code:
\begin{minted}
{bash}
input="plassProteinsReduced"
for step in 1:maxStep
    # we do not use the cluster mmseqs command as it
    # already is a cascaded workfolw clustering
    mmseqs search $input $input searchStep$step tmpDir
    mmseqs clust $input searchStep$step clusteringStep$step
    mmseqs result2repseq ...
    input=...
done

# Then merge the clustering steps
mmseqs mergeclusters input deepClusterDB ...


\end{minted}

Try your script with 3 steps, and check the clustering depth (number of clusters) at each step:
\begin{minted}
{bash}
wc -l clusteringStep*.index
\end{minted}

What do you notice ?


To even more deeply cluster your protein set,  one idea is to create a cascaded clustering where the sequence search at every iteration is replaced by a profile to sequence search. Code your own workflow that will be using the MMSeqs2 \texttt{result2profile} commands.

Did you manage to cluster more deeply ?

You can get the distribution of your cluster sizes by calling\begin{minted}
{bash}
# get the size of every cluster
mmseqs result2stats plassProteinsReduced plassProteinsReduced\
deepClusterDB deepClusterDB.clusterSizes --stat linecount
# show the distribution
cat deepClusterDB.clusterSizes|tr -d '\0'|sort -n|uniq -c
\end{minted}

You can compare it to your first cascaded clustering.



\subsection{Abundance analysis}
TODO, normalize by the gene length
Let's check the most abundant genes in our dataset. To this end, we want to map the orfs from the reads on the protein catalog, and count the number of hits on each of the proteins.
Code an MMSeqs2 workflow that:
\begin{itemize}
    \item extracts the ORFs from the reads (\texttt{extractorfs}),
    \item map them on the proteins (\texttt{prefilter} with option \texttt{-s 1} since mapping calls for high sequence identity),
    \item score the prefilter hits with a gapless alignment (\texttt{rescorediagonal} with option \texttt{-c 1 --cov-mode 2 --min-seq-id 0.95 --rescore-mode 2 -e 0.000001} to have significant hits and fully covered by the protein sequence),
    \item sort the hits by evalue (\texttt{filterdb} and guess the right flags!),
    \item keep the best mapping target (\texttt{filterdb} with flag \texttt{--extract-lines 1}),
    \item in the database output from the last step, every entry is a read-orf. Now you should transpose the database so that each contig is an entry, and the data is the list of mapped read-orfs (\texttt{swapresults}),
    \item count the number of mapped read-orf (\texttt{result2stats}).
\end{itemize}

To output the abundances as a TSV format, there is a hacky way:
\begin{minted}
{bash}
# Create a flat file
mmseqs result2flat plassProteinsReduced plassProteinsReduced\
mapAbundances mapAbundances.flat

# Check out the results
head mapAbundances.flat

# Transform this fasta-like format to TSV
awk '$0~/^>/{name=$0;next}{print name"\t" $0}'\
mapAbundances.flat|\
sort -n -k2,2|sed 's/>//' >abundances.tsv
\end{minted}

\subsection{Re-create the linclust workflow... if you have time :)}

Based on the explanation of the Linclust algorithm, try to code its workflow using:
\begin{itemize}
    \item \texttt{kmermatcher}
    \item \texttt{rescorediagonal}
    \item \texttt{clust}
\end{itemize}

The real Linclust code is slightly more involved as it integrates a redundancy reduction step (the \texttt{pre_clust} prefiltering by high Hamming distance) \url{/home/ubuntu/software/MMseqs2/data/linclust.sh}, and use a trick using \texttt{filterdb --filter-file} to apply the workflow you just built only on the \textit{non-redundant} entries. You can also spot in the end a merging step to recover the redundant part in the final clustering.


\section{Conclusion}

We hope that you are more familiar with the MMSeqs2 environment, and that you enjoy its modularity and flexibility for creating new workflows. Due to virtual machine constraints and that we were willing to spend time only on practicing we chose a rather small metagenomic dataset, but using MMSeqs2 on bigger datasets should convince you of its scalability.

Please help us by giving critical feedback on this tutorial!


\bibliographystyle{plain}
\bibliography{references}
\end{document}
